{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6f9132d",
   "metadata": {},
   "source": [
    "# 0. Download data\n",
    "\n",
    "1 download the data in huggingface;\n",
    "\n",
    "[Data](https://huggingface.co/datasets/Jungle15/GDP-HMM_Challenge)\n",
    "\n",
    "2 change the `npz_path` in the `meta_files/meta_data.csv` depending on the data path on your local machine.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5c857e-340f-4c27-ba3a-6bd7bea5f56b",
   "metadata": {},
   "source": [
    "## 1. Python Environment\n",
    "\n",
    "The baseline has been tested with Python 3.10, PyTorch 2.1.2, and MONAI 1.4.0. Similar versions should work but have not been tested by organizers. \n",
    "\n",
    "The other necessary pakages can be installed by:\n",
    "\n",
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c386e22-0f31-41d7-9674-1422aa754d31",
   "metadata": {},
   "source": [
    "## 2. Preprocess Downloaded Data\n",
    "\n",
    "Preprocess the downloaded data using the code [data_preprocess.py](./data_preprocess.py). Please revise 'csv_root' and 'dataset_save_root' according to the downloaded data path and desired save path for preprocessed data on your local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95fa33d-e04d-4004-b44f-77a1f0b6b5a4",
   "metadata": {},
   "source": [
    "## 3. Import neccessary packages and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63cb291c-5e87-4a61-94c4-ccdf8d6bb39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from nnunet_mednext import create_mednext_v1\n",
    "import data_loader_lightning\n",
    "import yaml\n",
    "\n",
    "cfig = yaml.load(open('config_files/config_dummy.yaml'), Loader=yaml.FullLoader)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4531415-8ffb-46c9-81d9-b357785a76d1",
   "metadata": {},
   "source": [
    "The config includes two major parts: loader_params and model_params. We will introduce them more in the following. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfdb9d4d-cc8d-435c-87f6-7a5418c6d0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_bs': 1,\n",
       " 'val_bs': 1,\n",
       " 'csv_root': 'meta_files/meta_data_dummy.csv',\n",
       " 'csv_root_validation': 'meta_files/meta_data_sanity_validation.csv',\n",
       " 'csv_HaN_OAR_priority_root': 'meta_files/HaN_OAR_update.csv',\n",
       " 'csv_LUNG_OAR_priority_root': 'meta_files/LUNG_OAR_update.csv',\n",
       " 'scale_dose_dict': 'meta_files/PTV_DICT.json',\n",
       " 'pat_obj_dict': 'meta_files/Pat_Obj_DICT.json',\n",
       " 'num_workers': 4,\n",
       " 'down_HU': -1000,\n",
       " 'up_HU': 1000,\n",
       " 'denom_norm_HU': 500,\n",
       " 'in_size': [96, 128, 160],\n",
       " 'out_size': [96, 128, 160],\n",
       " 'CatStructures': False,\n",
       " 'dose_div_factor': 10}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfig['loader_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "055c9bff-c98d-44ab-8aed-217c1e4832d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_input_channels': 6,\n",
       " 'out_channels': 1,\n",
       " 'model_id': 'A',\n",
       " 'kernel_size': 3,\n",
       " 'deep_supervision': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfig['model_params']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec80cde4-46fd-4cdc-bd60-3d79b3290be6",
   "metadata": {},
   "source": [
    "## 3. Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fa66dea-fdad-490e-99b0-ee84a3953dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = data_loader_lightning.GetLoader(cfig = cfig['loader_params'])\n",
    "train_loader =loaders.train_dataloader()\n",
    "val_loader = loaders.train_val_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd9cc78-89cd-4e27-8d2e-e32ed6d6375e",
   "metadata": {},
   "source": [
    "## 4. Network structure\n",
    "\n",
    "As mentioned earlier, we use MedNeXt as the backbone. Please follow the MedNeXt official instructions to adjust the structure. The example we use is as below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de8de195-b584-4f51-afcb-67002a4f09df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_mednext_v1( num_input_channels = cfig['model_params']['num_input_channels'],\n",
    "  num_classes = cfig['model_params']['out_channels'],\n",
    "  model_id = cfig['model_params']['model_id'],          # S, B, M and L are valid model ids\n",
    "  kernel_size = cfig['model_params']['kernel_size'],   # 3x3x3 and 5x5x5 were tested in publication\n",
    "  deep_supervision = cfig['model_params']['deep_supervision']   \n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c19968b-6d82-4785-992f-8f13d1043892",
   "metadata": {},
   "source": [
    "## 5. Define loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbe7bca4-a3f1-44b3-b1d8-7af538ad865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Loss import L1_DVH_Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=cfig['lr'])\n",
    "criterion = L1_DVH_Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5c4753-af88-4384-84f9-58a3618a6532",
   "metadata": {},
   "source": [
    "## 6. Training \n",
    "\n",
    "Then, you are ready to with training loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76d5ef64-e046-43b6-ad6b-df3b767cbb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [1/4], Loss: 0.8451\n",
      "Epoch [1/10], Step [2/4], Loss: 0.5782\n",
      "Epoch [1/10], Step [3/4], Loss: 0.6047\n",
      "Epoch [1/10], Step [4/4], Loss: 0.4416\n",
      "Epoch [2/10], Step [1/4], Loss: 0.3344\n",
      "Epoch [2/10], Step [2/4], Loss: 0.3432\n",
      "Epoch [2/10], Step [3/4], Loss: 0.3887\n",
      "Epoch [2/10], Step [4/4], Loss: 0.4147\n",
      "Epoch [3/10], Step [1/4], Loss: 0.3649\n",
      "Epoch [3/10], Step [2/4], Loss: 0.3414\n",
      "Epoch [3/10], Step [3/4], Loss: 0.3452\n",
      "Epoch [3/10], Step [4/4], Loss: 0.3025\n",
      "Epoch [4/10], Step [1/4], Loss: 0.3975\n",
      "Epoch [4/10], Step [2/4], Loss: 0.3536\n",
      "Epoch [4/10], Step [3/4], Loss: 0.3613\n",
      "Epoch [4/10], Step [4/4], Loss: 0.2943\n",
      "Epoch [5/10], Step [1/4], Loss: 0.4379\n",
      "Epoch [5/10], Step [2/4], Loss: 0.3407\n",
      "Epoch [5/10], Step [3/4], Loss: 0.3730\n",
      "Epoch [5/10], Step [4/4], Loss: 0.2729\n",
      "Epoch [6/10], Step [1/4], Loss: 0.2992\n",
      "Epoch [6/10], Step [2/4], Loss: 0.2890\n",
      "Epoch [6/10], Step [3/4], Loss: 0.3367\n",
      "Epoch [6/10], Step [4/4], Loss: 0.3219\n",
      "Epoch [7/10], Step [1/4], Loss: 0.2313\n",
      "Epoch [7/10], Step [2/4], Loss: 0.3964\n",
      "Epoch [7/10], Step [3/4], Loss: 0.2537\n",
      "Epoch [7/10], Step [4/4], Loss: 0.2233\n",
      "Epoch [8/10], Step [1/4], Loss: 0.2631\n",
      "Epoch [8/10], Step [2/4], Loss: 0.2472\n",
      "Epoch [8/10], Step [3/4], Loss: 0.3480\n",
      "Epoch [8/10], Step [4/4], Loss: 0.3165\n",
      "Epoch [9/10], Step [1/4], Loss: 0.3119\n",
      "Epoch [9/10], Step [2/4], Loss: 0.2160\n",
      "Epoch [9/10], Step [3/4], Loss: 0.2587\n",
      "Epoch [9/10], Step [4/4], Loss: 0.2751\n",
      "Epoch [10/10], Step [1/4], Loss: 0.2646\n",
      "Epoch [10/10], Step [2/4], Loss: 0.3618\n",
      "Epoch [10/10], Step [3/4], Loss: 0.3357\n",
      "Epoch [10/10], Step [4/4], Loss: 0.2229\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(cfig['num_epochs']):\n",
    "    model.train()\n",
    "    for i, data_dict in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        outputs = model(data_dict['data'].to(device))\n",
    "        loss = criterion(outputs, data_dict['label'].to(device),data_dict['PTV'].to(device),data_dict['oar_serial'].to(device),data_dict['oar_parallel'].to(device),device)\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch [{epoch+1}/{cfig['num_epochs']}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cc0f6f",
   "metadata": {},
   "source": [
    "## 7. Train a complete model.\n",
    "To train a complete model, please run the codes [train.py](./train.py) with the [configure file](./config_files/config_AGMedNext.yaml) and [train_upkern.py](./train_upkern.py) with the [configure file](./config_files/config_AGMedNext_UpKern.yaml) sequentially. \n",
    "\n",
    "Please revise the `npz_path` in the `meta_files/meta_data.csv` depending on the preprocessed data path on your local machine before model training:\n",
    "\n",
    "python train.py config_files/config_AGMedNext.yaml\n",
    "\n",
    "python train_upkern.py config_files/config_AGMedNext_UpKern.yaml\n",
    "\n",
    "python train_upkern.py config_files/config_AGMedNext_UpKern7.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb94e95d",
   "metadata": {},
   "source": [
    "## 8. Model inference\n",
    "To use the trained model for dose prediction, please run [inference.py](./inference.py)\n",
    "\n",
    "Example usage:\n",
    "\n",
    "python inference.py config_files/config_infer.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2590ab9",
   "metadata": {},
   "source": [
    "## 9. Model evaluation\n",
    "To evaluate the dose prediction accuracy of the trained model, please run [evaluation.py](./evaluation.py)\n",
    "\n",
    "Example usage:\n",
    "\n",
    "python evaluation.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GDP-HHM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
